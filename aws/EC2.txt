It's the most popular and the most important AWS offering.

EC2 stands for Elastic Compute Cloud. It is AWS's Infrastructure as a Service.
It mainly consists of:
Renting Virtual Machines - EC2
Storing data on virtual drives - Elastic Block Store - EBS
Distributing the load across machines - Elastic Load Balancing - ELB
Auto Scaling the services using an Auto Service Group - ASG

Knowing EC2 is the most important step in learning how AWS works or the Cloud works in general.

When we are configuring the EC2 instance, we need to decide upon:
  Which OS to choose - Either Linux, MacOS or Windows
  How much compute power - Cores
  How much memory - RAM
  How much storage space:
    Network attached - EBS & Elastic File System - EFS
    Hardware - EC2 instance store
  Public IP, Private IPs
  Security Groups - Firewalls
  Bootstrap script - Configure the first launch - EC2 User Data

  The above is just like buying a laptop - We choose the OS, CPU, RAM, Hard Drive. We just have a few extra things over here such as Network, Firewall and Bootup script.

EC2 User Data:
  Bootstrap means launching commands when a machine starts. It's possible to bootstrap our EC2 instances using EC2 User Data Scripts. It runs once when the system is booted.
  EC2 User data is used to automate the boot tasks such as:
    Installing updates
    Installing software
    Downloading common files from the internet, etc.

  Boot scripts run only with the root user. So, it'll require to be run as `sudo` from the SSH shell.

EC2 Instance Types:
Some of the instances are as follows:
```
t2.xlarge - 4 Cores, 16GB RAM
c5d.4xlarge - 16 Cores, 32GB RAM
m5.8xlarge - 32 Cores, 128GB RAM
r5.16xlarge - 64 Cores, 512GB RAM - Highest possible.
```
`t2.micro` instance - 750 hours/month is sufficient for the training, which has got 1 CPU core & 1GB RAM. It's storage is on the Elastic Block store. 30 GB of EBS is included in the Free Tier.

Launching an EC2 instance:
My first instance details:
Name: My First Instance
OS: Amazon Linux 2023 AMI
Architecture: 64bit-x86
Instance Type: t2.micro

Created a new Key Pair for SSH login into the instance. Downloaded it as well.
I've allowed logging in via SSH into my EC2 instance from anywhere.
Created a User Data Script to launch it, it's written in bash as follows:
```
#!/bin/bash
# Use this for your user data (script from top to bottom)
# install httpd (Linux 2 version)
yum update -y
yum install -y httpd
systemctl start httpd
systemctl enable httpd
echo "<h1>Hello, World from my first EC2 Instance - $(hostname -f)</h1>" > /var/www/index.html
```

Here we can now view our Webpage via `index.html` that was just created via our script above.

There are different types of instances in EC2:
  General Purpose:
    It has a balance of Memory, Compute and Networking resources. It's ideal for resources in equal proportions, such as web servers and code.
    Such instances come under the `t` classes of instances.
  Compute Optimized:
    It is compute resources optimized. It's used for compute intensive tasks that require high performance processors.
    It's used for batch processing workloads, also used for media transcoding like converting images or videos into multiple sizes or compressing them.
    Game servers, Machine Learning, High performance web servers.
    Such instances come under the `c` classes of instances.
  Memory Optimized:
    It is memory optimized. Fast performance for workloads which Pprocess large datasets in memory.
    High performance SQL, NoSQL queries.
    Distributed Web Caches.
    Business Intelligence and Real Time processing of big unstructured data.
    Such instances come under the `r`, `x`, `z` classes of instances.
  Storage Optimized:
    It is storage optimized. Great for storage intensive tasks, that require high sequential, read and write access to data sets on local storage.
    High frequency Online Transaction Processing Systems(OLTP)
    Relational & NoSQL databases
    Cache for in-memory databases(Redis, Memcached)
    Data warehousing
    Distributed file systems
    Such instances come under the `i`, `d`, `h` classes of instances.
  Accelerated Computing:

Naming conventions of EC2 instances:
  Suppose `m5.2xlarge` is the name of the instance. Then,
  `m` is the instance class
  `5` is the generation of the instance
  `2xlarge` is the size of the instance class

Security Groups in EC2:
  These security groups are basically firewalls around our EC2 instances. This is a fundamental building block of our AWS Networking security.
  It controls how traffic is allowed into and out of our EC2 instances. It wraps our EC2 instance. EC2 instance won't even be notified of the traffic that is blocked by the security group.
  Security groups have got only `allow` rules inside them.
  It can reference by IP address or by Security Group.
  It's a good practice to maintain one security group for SSH access.

  Security groups regulate:
  Access to ports of our instance
  Authorized IP Ranges to access our instance
  It controls Inbound - From internet to the instance and Outbound - From instance to the internet, traffic of the instance

  Rules of Security Groups:
  One Security group can be attached to multiple instances. An instance can have multiple Security Groups too.
  Security Groups are locked down to a region or VPC combination.
  By default all inbound traffic is blocked.
  By default all outbound traffic is allowed.
  When we get a `Connection refused` error then the traffic went through the security group and hit the instance.
  When the Security group blocks access to an instance then we always get a `Connection Timed Out` error.
  We can reference one Security Group from another Security Group as well.

  Ports to remember for Security Groups:
  22 - SSH - To log into an instance via Secure Shell.
  21 - FTP - To upload files to the instance
  22 - SFTP - To securely upload files using SSH to the instance.
  53 - DNS - Resolving Domain Names into IP Addresses.
  80 - HTTP - Access unsecured websites.
  443 - HTTPS - Access secured websites.
  3306 - Database Connections like MySQL.
  3389 - RDP(Remote Desktop Protocol) - A Windows only alternative instance port to log into an instance like SSH.

  These ports are for Transport layer of TCP/IP Protocol.
  While many ports are non-privileged, - anyone can use them without special permission—some require root permissions. Ports 1-1023 are called 'well-known ports' and require root permissions before a server can listen to them.
  It’s a good practice to avoid running web servers as root, assign minimal permissions to services, and use nonprivileged ports when possible.
  That’s why sometimes we can see ports 8080 for HTTP and ports 6433 for HTTPS - they’re non-privileged.

  Thus for example we can block accessing of an EC2 instance from HTTP to make it available for access using SSH only, vice versa can also be true.
  When we block or remove access of something from EC2 then it always gives a timeout. Thus a timeout is basically an indication of Security Group configs.
  It's true for SSH, HTTP, or any other protocol.

SSH into an EC2 instance:
  SSH is one of the most important function. It allows us to control a remote machine, all using the command line.

  We can access our EC2 instance using our terminal. We have to use access keys `.pem` file provided when we create our instance using the key pair.
  Just like Cloud Shell - EC2 Instance Connect is a browser based solution for connecting to an EC2 instance via the browser itself.
  But I prefer the normal SSH via terminal, because it's easier to access and it's not even chargeable, however just like Cloud Shell, EC2 Instance Connect is chargeable. The SSH access is also blocked through Instance Connect if we revoke the permissions of inbound traffic through SSH.

  We access our instance using our instance's public IP.

Purchasing options of EC2 instances - Very important:
The entire quiz of the fundamentals of EC2 instances was based on this section itself. Questions are asked about purchasing suggestions of EC2 instances based on a scenario or a requirement.
  Spot Instances & Spot Fleet:

Recycle Bin AWS Service:
  This AWS Service helps us recover deleted Volume Snapshots and Amazon Machine Images(AMIs) based on the retention rule which we define for our Recycle Bin.
  Recycle Bin only supports EBS Snapshots and AMIs only. Nothing else is supported for backup after deletion.
  We have to create retention rules for the resources to be retained after deletion. Each retention rule will have a retention time attached to it.
  One retention rule is for one type of resource only. We have to create different retention rules for different types of resources.
  For example one retention rule for AMIs, one for EBS Snapshots.

EC2 Instance storage:
  Elastic Block Store(EBS) Volume:
    We can store data in Network drive attached to our EC2 instances using EBS Volume while they run. It's like a Network USB stick attached to an EC2 instance.
    It allows our instances to persist data even after our instance is terminated.
    Since EBS volumes are network drives, they can be detached from one EC2 instance and attached to another instance very quickly.
    Multiple EBS volumes can be attached to EC2 instances. But one EBS volume can't be attached to multiple instances at a time.
    But EBS volumes are locked to a specific AZ or Region. We can't even change see the EC2 instances outside our AZ or Region when we want to attach a volume to any of our EC2 instances. We can see the EC2 instances only available in our own AZ or Region.
    30 GB of free EBS Volume is eligible for Free Tier.
    But if we really want to move an EBS Volume then we can take a snapshot of the volume and move it across AZs or Regions as well.
    By default the EBS Root Volume is deleted on termination of an EC2 instance. But we can change it if we want.
    When we create an EBS Volume, we generally use the same availability zone as the EC2 instance resides in as a rule of thumb.

    Snapshots of EBS Volumes:
    We can take a snapshot of our EBS volume at any point in time. It's typically preferred to detach an EBS volume before we take it's snapshot.
    The point is that we can transfer snapshots between AZs and Regions of EBS Volumes. Then it can be imported(in short Create a Volume from a Snapshot using the Volume from Snapshot feature) and used in another EC2 instance in another region as well.
    EBS Snapshot archive is cold storage of an EBS Volume snapshot and is cheaper. But if we want to restore an EBS Snapshot in cold storage, it needs typically 24 to 72 hours. It's slower.
    But when we simply delete a Snapshot then it's moved to Recycle Bin which can be restored based on the retention time of the Recycle Bin. It can be anywhere between 1 day or 1 year.

    EBS Volume types:
    EBS Volumes are characterized by Size, throughput and and IOPs(I/O operations/sec).
    gp2, gp3 - SSD - General purpose SSD volumes. They both have a balance of throughput and storage.
    io1 io2 - SSD - Highest performance SSDs for mission critical low latency stuff.
    st1, sc1(Cold Storage) - HDD - Both can be used as storage. Being HDDs, they are lower in IOPs capacity, because their focus is more on storage than throughput. They are low cost.
    Only gp2, gp3 and io1, io2 can be used as boot volumes where the OS resides.

    EBS Volumes Multi Attach:
    Multi attach basically means that the same EBS Volume can be attached to multiple EC2 instances in the same AZ.
    It's supported only by the io1, io2 family. The provisioned EBS Volumes - PIOPs support the multi attach feature.
    Each EC2 instance has full read-write permissions to the EBS Volume. Because it's designed specifically only for throughput.
    It can be attached to a max of 16 EC2 instances at a time.

  Amazon Machine Image(AMI):
    AMIs power our EC2 isntances. An AMI is a customization of an EC2 instance. We can add our own software, configs, OS, monitoring, etc.
    Until now, in our EC2 instances, we used pre shipped AMIs provided by AWS. However, we can build our own images from existing EC2 instances as Snapshots and create our own machine images which can be used for other EC2 instances as needed.
    Amazon Machine Image is basically an image which contains pre packaged software installed in it, because we have used a snapshot from another EC2 instance as our base which already has the necessary software installed in it. It also leads to faster boot times and load times. Thus we can leverage those previously done installations and use it in our machine images. Thus making our work easier.
    The big advantage of AMIs is that it can be built in one region and can be copied and used across regions, thus getting handy for leveraging the AWS Global Infra.

    AMI creation process:
    Start and EC2 instance and Customize it.
    Stop the instance.
    Build an AMI - It'll create EBS snapshots in the background.
    Launch instances from other AMIs.

  EC2 Instance Store - High performance hard drive, but temporary storage, cleaned up on instance termination:
    EBS Volumes are network drives but with limited performance.
    We should use EC2 instance store if we wanna have high performance, then we attach a hard disk to it using EC2 Instance Store.
    But the bad thing about it is that if we stop an EC2 instance, then the data inside the EC2 Instance Store is also lost.
    The ideal use case for this is then store a buffer, cache, scratch data, tmp files, etc.
    Backups and replication can happen on it though, but it's to be done by ourselves.

  Amazon Elastic File System - EFS:
  EFS is a Network file system, and because it's a Network File System, it can be mounted on to many EC2 instances. Unlike EBS, it can be mounted on to multiple AZs.
  It is very expensive though. It's 3 times expensive as gp2 volumes, due to high availability and scalability.
  Just like an EC2 instance, we need to secure our EFS using a security group. It's governed by NFS v4.1 protocol.
  It has a POSIX file system, that's why it's compatible with Linux AMIs only and not with Windows systems.
  It has infinite capacity. It scales as per the usage.

  The frequently accessed files are stored inside the EFS whereas if a time limit crosses, something like 30 days, it'll be moved to cold storage for cost saving purposes.

EC2 Hibernate:
